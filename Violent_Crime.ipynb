{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Violent Crime.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Import libraries and data"
      ],
      "metadata": {
        "id": "QRo5Hl7k8Hjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "4glNq_DC8O3B"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv('2019 income data by county.csv', encoding='latin-1', thousands=',')\n",
        "df2 = pd.read_csv('co-est2019-alldata.csv', encoding='latin-1', thousands=',')\n",
        "df3 = pd.read_csv('Table_10_Offenses_Known_to_Law_Enforcement_by_State_by_Metropolitan_and_Nonmetropolitan_Counties_2019.csv', thousands=',')"
      ],
      "metadata": {
        "id": "9y3uTlr48PxJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data cleaning\n",
        "Some data cleaning done in Excel, including use of VLookup."
      ],
      "metadata": {
        "id": "UkeTRAzmwiYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df1[df1.LineCode == 3]\n",
        "df1['State1'] = df1['State1'].str.strip()\n",
        "df1['County'] = df1['County'].str.strip()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7wEp1ydteL1",
        "outputId": "ecf5b1a8-1493-4eb0-a611-be6b657d0bed"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Join data sets"
      ],
      "metadata": {
        "id": "PYbV58t7-Bqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import reduce\n",
        "data_frames = [df3, df1, df2]\n",
        "data = reduce(lambda  left,right: pd.merge(left,right,on=['County', 'State1'],\n",
        "                                            how='outer', validate = 'many_to_many'), data_frames)"
      ],
      "metadata": {
        "id": "lOqANuOC-JKp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.rename(columns={'Violent\\ncrime': 'Violent crime'})"
      ],
      "metadata": {
        "id": "yS2cjHe6ODJe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Removing missing data"
      ],
      "metadata": {
        "id": "Q5KHAGtlBm1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.dropna(subset=['2019', 'Metro', 'POPESTIMATE2019', 'Violent crime'])"
      ],
      "metadata": {
        "id": "4889nGiHBpkX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compression_opts = dict(method='zip',\n",
        "#                       archive_name='out.csv')  \n",
        "#data.to_csv('out.zip', index=False,\n",
        "#          compression=compression_opts)"
      ],
      "metadata": {
        "id": "Y_aIU-PuFe9g"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create X and y variables"
      ],
      "metadata": {
        "id": "6Shc4Tg_w_Gj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data[['2019', 'POPESTIMATE2019', 'Metro']].values\n",
        "X = np.asarray(X).astype(np.float32)\n",
        "y = data['Violent crime'].values"
      ],
      "metadata": {
        "id": "YZbEY-7vxE-r"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Split into training and test set"
      ],
      "metadata": {
        "id": "IwW2hjjvIKOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
      ],
      "metadata": {
        "id": "CmtWD1HUIMno"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Feature Scaling"
      ],
      "metadata": {
        "id": "54RyVSZdIOqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train[:, :-1] = sc.fit_transform(X_train[:, :-1])\n",
        "X_test[:, :-1] = sc.transform(X_test[:, :-1])"
      ],
      "metadata": {
        "id": "JhXz5wBtIPzw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Regression models"
      ],
      "metadata": {
        "id": "yrbXTfcRIfk3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Multiple linear regression"
      ],
      "metadata": {
        "id": "xF4HTTlvSchP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW_RFGAAIiPX",
        "outputId": "abd592a7-cd20-44e3-e0b8-ad5d4627d6d7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Support vector regression"
      ],
      "metadata": {
        "id": "bTdj7a2eSg7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "regressor = SVR(kernel = 'rbf')\n",
        "regressor.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMfLkGUZSo1n",
        "outputId": "8eb20092-1826-45d6-bfd2-1fd010d9d741"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVR()"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Random forest regression"
      ],
      "metadata": {
        "id": "XAktpqyjS0PP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "regressor = RandomForestRegressor(n_estimators = 100, random_state = 0)\n",
        "regressor.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuwpPOdpS5uG",
        "outputId": "2d19646f-82d6-4380-849e-787564a4c12e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###XGBoost"
      ],
      "metadata": {
        "id": "taEWCemgTQLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "regressor = XGBRegressor(objective='reg:squarederror')\n",
        "regressor.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yPV-tobTScd",
        "outputId": "3a9e6faa-de8b-4e24-d7e1-628e284fdcce"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(objective='reg:squarederror')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Artificial neural network"
      ],
      "metadata": {
        "id": "saCVZyX2UJgA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann = tf.keras.models.Sequential()\n",
        "ann.add(tf.keras.layers.Dense(units=9, input_dim=3, activation='relu'))\n",
        "ann.add(tf.keras.layers.Dense(units=9, activation='relu'))\n",
        "ann.add(tf.keras.layers.Dense(units=9, activation='tanh'))\n",
        "ann.add(tf.keras.layers.Dense(units=1))\n",
        "ann.compile(loss='mean_squared_error', optimizer='adam', metrics = ['Accuracy'])"
      ],
      "metadata": {
        "id": "jW41iJC1UNI2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann.fit(X_train, y_train, batch_size = 32, epochs = 150)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_W8QT80Vo8m",
        "outputId": "e5fe7cf0-62e7-4b1e-bfe3-0fa4226e3148"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "53/53 [==============================] - 1s 4ms/step - loss: 116845.6172 - Accuracy: 0.0601\n",
            "Epoch 2/150\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 116768.0547 - Accuracy: 0.0613\n",
            "Epoch 3/150\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 116694.0391 - Accuracy: 0.0506\n",
            "Epoch 4/150\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 116599.0703 - Accuracy: 0.0321\n",
            "Epoch 5/150\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 116498.3594 - Accuracy: 0.0310\n",
            "Epoch 6/150\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 116404.8125 - Accuracy: 0.0310\n",
            "Epoch 7/150\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 116320.4375 - Accuracy: 0.0310\n",
            "Epoch 8/150\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 116237.7344 - Accuracy: 0.0310\n",
            "Epoch 9/150\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 116155.6484 - Accuracy: 0.0310\n",
            "Epoch 10/150\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 116076.1250 - Accuracy: 0.0310\n",
            "Epoch 11/150\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 116000.0547 - Accuracy: 0.0310\n",
            "Epoch 12/150\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 115925.6641 - Accuracy: 0.0310\n",
            "Epoch 13/150\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 115854.0859 - Accuracy: 0.0310\n",
            "Epoch 14/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 115788.1328 - Accuracy: 0.0310\n",
            "Epoch 15/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 115721.8594 - Accuracy: 0.0310\n",
            "Epoch 16/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 115657.2578 - Accuracy: 0.0310\n",
            "Epoch 17/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 115592.8281 - Accuracy: 0.0310\n",
            "Epoch 18/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 115529.0703 - Accuracy: 0.0310\n",
            "Epoch 19/150\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 115467.8281 - Accuracy: 0.0310\n",
            "Epoch 20/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 115408.3828 - Accuracy: 0.0310\n",
            "Epoch 21/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 115349.5312 - Accuracy: 0.0310\n",
            "Epoch 22/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 115290.8594 - Accuracy: 0.0310\n",
            "Epoch 23/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 115235.1328 - Accuracy: 0.0310\n",
            "Epoch 24/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 115177.5781 - Accuracy: 0.0310\n",
            "Epoch 25/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 115121.3359 - Accuracy: 0.0310\n",
            "Epoch 26/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 115066.6562 - Accuracy: 0.0310\n",
            "Epoch 27/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 115012.2578 - Accuracy: 0.0310\n",
            "Epoch 28/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 114957.9844 - Accuracy: 0.0310\n",
            "Epoch 29/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 114905.4219 - Accuracy: 0.0310\n",
            "Epoch 30/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 114852.0938 - Accuracy: 0.0310\n",
            "Epoch 31/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 114800.5391 - Accuracy: 0.0310\n",
            "Epoch 32/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 114750.3125 - Accuracy: 0.0310\n",
            "Epoch 33/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 114699.1016 - Accuracy: 0.0310\n",
            "Epoch 34/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 114649.5547 - Accuracy: 0.0310\n",
            "Epoch 35/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 114600.3984 - Accuracy: 0.0310\n",
            "Epoch 36/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 114551.3594 - Accuracy: 0.0310\n",
            "Epoch 37/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 114503.7734 - Accuracy: 0.0310\n",
            "Epoch 38/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 114456.9297 - Accuracy: 0.0310\n",
            "Epoch 39/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 114408.9297 - Accuracy: 0.0310\n",
            "Epoch 40/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 114362.4219 - Accuracy: 0.0310\n",
            "Epoch 41/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 114316.4844 - Accuracy: 0.0310\n",
            "Epoch 42/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 114270.1250 - Accuracy: 0.0310\n",
            "Epoch 43/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 114224.1328 - Accuracy: 0.0310\n",
            "Epoch 44/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 114178.0156 - Accuracy: 0.0310\n",
            "Epoch 45/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 114132.4609 - Accuracy: 0.0310\n",
            "Epoch 46/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 114084.8750 - Accuracy: 0.0310\n",
            "Epoch 47/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 114038.1406 - Accuracy: 0.0310\n",
            "Epoch 48/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113990.3203 - Accuracy: 0.0310\n",
            "Epoch 49/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113942.9922 - Accuracy: 0.0310\n",
            "Epoch 50/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113896.5547 - Accuracy: 0.0310\n",
            "Epoch 51/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113850.1406 - Accuracy: 0.0310\n",
            "Epoch 52/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113803.8125 - Accuracy: 0.0310\n",
            "Epoch 53/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113758.2734 - Accuracy: 0.0310\n",
            "Epoch 54/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113710.5703 - Accuracy: 0.0310\n",
            "Epoch 55/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113665.1406 - Accuracy: 0.0310\n",
            "Epoch 56/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113618.0078 - Accuracy: 0.0310\n",
            "Epoch 57/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113570.8125 - Accuracy: 0.0310\n",
            "Epoch 58/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113525.6641 - Accuracy: 0.0310\n",
            "Epoch 59/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113477.3125 - Accuracy: 0.0310\n",
            "Epoch 60/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113429.1875 - Accuracy: 0.0310\n",
            "Epoch 61/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113382.3047 - Accuracy: 0.0310\n",
            "Epoch 62/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113338.1641 - Accuracy: 0.0310\n",
            "Epoch 63/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113289.7656 - Accuracy: 0.0310\n",
            "Epoch 64/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113244.2969 - Accuracy: 0.0310\n",
            "Epoch 65/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113197.3203 - Accuracy: 0.0310\n",
            "Epoch 66/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113153.0078 - Accuracy: 0.0310\n",
            "Epoch 67/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113107.2344 - Accuracy: 0.0310\n",
            "Epoch 68/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113063.0469 - Accuracy: 0.0310\n",
            "Epoch 69/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113018.7031 - Accuracy: 0.0315\n",
            "Epoch 70/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112976.0547 - Accuracy: 0.0315\n",
            "Epoch 71/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112931.7266 - Accuracy: 0.0310\n",
            "Epoch 72/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112889.4609 - Accuracy: 0.0333\n",
            "Epoch 73/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112847.3125 - Accuracy: 0.0339\n",
            "Epoch 74/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112804.6875 - Accuracy: 0.0333\n",
            "Epoch 75/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112762.5781 - Accuracy: 0.0333\n",
            "Epoch 76/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112721.7891 - Accuracy: 0.0321\n",
            "Epoch 77/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112681.0859 - Accuracy: 0.0345\n",
            "Epoch 78/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112638.4609 - Accuracy: 0.0315\n",
            "Epoch 79/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112597.6016 - Accuracy: 0.0327\n",
            "Epoch 80/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112556.9219 - Accuracy: 0.0310\n",
            "Epoch 81/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112516.7891 - Accuracy: 0.0304\n",
            "Epoch 82/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112478.0703 - Accuracy: 0.0333\n",
            "Epoch 83/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112437.1719 - Accuracy: 0.0304\n",
            "Epoch 84/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112396.7422 - Accuracy: 0.0304\n",
            "Epoch 85/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112357.2031 - Accuracy: 0.0310\n",
            "Epoch 86/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112317.7031 - Accuracy: 0.0310\n",
            "Epoch 87/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112277.1719 - Accuracy: 0.0304\n",
            "Epoch 88/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112238.0156 - Accuracy: 0.0315\n",
            "Epoch 89/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112200.4922 - Accuracy: 0.0310\n",
            "Epoch 90/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112161.0781 - Accuracy: 0.0304\n",
            "Epoch 91/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112121.6094 - Accuracy: 0.0304\n",
            "Epoch 92/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112083.3203 - Accuracy: 0.0304\n",
            "Epoch 93/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112047.6875 - Accuracy: 0.0315\n",
            "Epoch 94/150\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 112007.2188 - Accuracy: 0.0310\n",
            "Epoch 95/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111969.1719 - Accuracy: 0.0310\n",
            "Epoch 96/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111931.2266 - Accuracy: 0.0310\n",
            "Epoch 97/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111893.2891 - Accuracy: 0.0310\n",
            "Epoch 98/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111856.6406 - Accuracy: 0.0310\n",
            "Epoch 99/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111818.6875 - Accuracy: 0.0310\n",
            "Epoch 100/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111780.6094 - Accuracy: 0.0310\n",
            "Epoch 101/150\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 111745.0547 - Accuracy: 0.0310\n",
            "Epoch 102/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111707.2344 - Accuracy: 0.0310\n",
            "Epoch 103/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111671.9062 - Accuracy: 0.0298\n",
            "Epoch 104/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111638.1406 - Accuracy: 0.0310\n",
            "Epoch 105/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111600.4375 - Accuracy: 0.0304\n",
            "Epoch 106/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111567.1641 - Accuracy: 0.0304\n",
            "Epoch 107/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111529.7109 - Accuracy: 0.0321\n",
            "Epoch 108/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111492.2188 - Accuracy: 0.0298\n",
            "Epoch 109/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111456.7734 - Accuracy: 0.0310\n",
            "Epoch 110/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111423.7891 - Accuracy: 0.0310\n",
            "Epoch 111/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111387.9453 - Accuracy: 0.0310\n",
            "Epoch 112/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111352.7344 - Accuracy: 0.0310\n",
            "Epoch 113/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111318.2344 - Accuracy: 0.0310\n",
            "Epoch 114/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111283.1250 - Accuracy: 0.0304\n",
            "Epoch 115/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111250.0078 - Accuracy: 0.0310\n",
            "Epoch 116/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111215.6953 - Accuracy: 0.0304\n",
            "Epoch 117/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111180.1719 - Accuracy: 0.0310\n",
            "Epoch 118/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111147.5156 - Accuracy: 0.0304\n",
            "Epoch 119/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111112.2266 - Accuracy: 0.0310\n",
            "Epoch 120/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111080.6406 - Accuracy: 0.0304\n",
            "Epoch 121/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111046.0859 - Accuracy: 0.0304\n",
            "Epoch 122/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111013.4453 - Accuracy: 0.0321\n",
            "Epoch 123/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110979.4375 - Accuracy: 0.0304\n",
            "Epoch 124/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110948.5078 - Accuracy: 0.0310\n",
            "Epoch 125/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110913.5234 - Accuracy: 0.0315\n",
            "Epoch 126/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110880.4844 - Accuracy: 0.0304\n",
            "Epoch 127/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110850.3594 - Accuracy: 0.0304\n",
            "Epoch 128/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110816.3359 - Accuracy: 0.0310\n",
            "Epoch 129/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110782.9922 - Accuracy: 0.0310\n",
            "Epoch 130/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110751.9531 - Accuracy: 0.0304\n",
            "Epoch 131/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110720.5547 - Accuracy: 0.0304\n",
            "Epoch 132/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110686.9922 - Accuracy: 0.0304\n",
            "Epoch 133/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110657.5156 - Accuracy: 0.0298\n",
            "Epoch 134/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110625.0312 - Accuracy: 0.0310\n",
            "Epoch 135/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110592.1250 - Accuracy: 0.0310\n",
            "Epoch 136/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110563.1172 - Accuracy: 0.0321\n",
            "Epoch 137/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110531.3203 - Accuracy: 0.0310\n",
            "Epoch 138/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110500.0156 - Accuracy: 0.0304\n",
            "Epoch 139/150\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 110470.4219 - Accuracy: 0.0321\n",
            "Epoch 140/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110438.6953 - Accuracy: 0.0304\n",
            "Epoch 141/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110409.3125 - Accuracy: 0.0310\n",
            "Epoch 142/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110379.4844 - Accuracy: 0.0310\n",
            "Epoch 143/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110349.2578 - Accuracy: 0.0310\n",
            "Epoch 144/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110321.6875 - Accuracy: 0.0304\n",
            "Epoch 145/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110290.3125 - Accuracy: 0.0310\n",
            "Epoch 146/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110259.7422 - Accuracy: 0.0315\n",
            "Epoch 147/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110235.1719 - Accuracy: 0.0304\n",
            "Epoch 148/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110203.0938 - Accuracy: 0.0304\n",
            "Epoch 149/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110174.9531 - Accuracy: 0.0310\n",
            "Epoch 150/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110148.9062 - Accuracy: 0.0310\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2d08305b50>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Predicting test set results"
      ],
      "metadata": {
        "id": "G3_LqjYuRFhm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = regressor.predict(X_test)\n",
        "np.set_printoptions(precision=2)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RU6iBi_GRlUu",
        "outputId": "e7b6d7a7-734e-493c-fbe9-7b9bcb2e98e7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6.01e+01  1.80e+01]\n",
            " [ 1.00e+01  0.00e+00]\n",
            " [ 2.70e+01  1.00e+01]\n",
            " [ 5.90e+01  5.00e+00]\n",
            " [-8.51e+00  4.00e+00]\n",
            " [ 2.45e+01  2.00e+00]\n",
            " [ 1.04e+02  1.60e+01]\n",
            " [ 7.52e+00  1.10e+01]\n",
            " [ 1.04e+02  6.60e+01]\n",
            " [ 9.80e+01  4.00e+01]\n",
            " [ 2.63e+01  4.00e+01]\n",
            " [ 2.04e+01  3.00e+00]\n",
            " [-7.84e+00  1.10e+01]\n",
            " [ 2.08e+02  1.04e+03]\n",
            " [ 1.79e+01  9.00e+00]\n",
            " [ 3.15e+01  1.10e+01]\n",
            " [ 3.22e+01  1.69e+02]\n",
            " [ 2.37e+01  1.00e+01]\n",
            " [ 8.18e+01  2.00e+01]\n",
            " [ 4.90e+01  8.30e+01]\n",
            " [ 6.58e+01  3.00e+01]\n",
            " [ 1.10e+02  5.40e+01]\n",
            " [ 3.89e+00  6.00e+00]\n",
            " [ 5.51e+01  7.30e+01]\n",
            " [ 6.73e+00  1.00e+00]\n",
            " [ 1.39e+02  1.18e+02]\n",
            " [ 1.35e+01  2.00e+00]\n",
            " [ 9.47e+01  1.00e+02]\n",
            " [ 7.05e+01  3.00e+00]\n",
            " [ 1.17e+02  1.17e+02]\n",
            " [ 1.13e+01  4.00e+00]\n",
            " [ 1.81e+01  0.00e+00]\n",
            " [-4.53e+00  6.00e+00]\n",
            " [ 3.54e+01  2.50e+01]\n",
            " [ 4.50e+01  4.00e+00]\n",
            " [ 7.37e+01  2.60e+01]\n",
            " [ 9.39e+01  3.20e+01]\n",
            " [ 4.42e+01  9.20e+01]\n",
            " [ 1.25e+00  2.20e+01]\n",
            " [ 4.95e+01  1.50e+01]\n",
            " [ 1.87e+02  0.00e+00]\n",
            " [-3.50e+00  3.10e+01]\n",
            " [ 5.04e+02  5.69e+02]\n",
            " [ 3.62e+01  1.00e+00]\n",
            " [ 6.02e+01  2.70e+01]\n",
            " [ 3.98e+01  4.00e+00]\n",
            " [ 1.40e+01  2.00e+00]\n",
            " [ 1.23e+02  3.70e+01]\n",
            " [ 2.87e+01  1.00e+00]\n",
            " [ 3.51e+01  1.40e+01]\n",
            " [ 3.51e+01  3.10e+01]\n",
            " [ 3.56e+01  2.50e+01]\n",
            " [ 3.87e+01  1.40e+01]\n",
            " [ 6.80e+01  6.00e+00]\n",
            " [ 4.34e+01  3.00e+01]\n",
            " [ 3.15e+01  2.00e+01]\n",
            " [ 3.01e+01  5.00e+00]\n",
            " [ 3.96e+01  4.50e+01]\n",
            " [ 3.39e+01  6.00e+01]\n",
            " [-5.98e+01  1.30e+01]\n",
            " [ 1.97e+01  1.30e+01]\n",
            " [ 2.33e+02  0.00e+00]\n",
            " [ 1.03e+02  0.00e+00]\n",
            " [ 2.25e+02  4.58e+02]\n",
            " [ 3.27e+01  7.00e+00]\n",
            " [-1.36e+01  4.00e+00]\n",
            " [ 1.40e+02  1.25e+02]\n",
            " [ 5.89e+01  4.70e+01]\n",
            " [ 7.29e+01  2.00e+00]\n",
            " [ 2.62e+01  2.10e+01]\n",
            " [ 5.30e+01  3.00e+01]\n",
            " [-2.14e+01  0.00e+00]\n",
            " [ 1.06e+02  7.50e+01]\n",
            " [ 2.93e+01  1.00e+01]\n",
            " [ 4.67e+01  1.70e+01]\n",
            " [ 7.02e+01  1.20e+01]\n",
            " [ 3.51e+01  3.00e+01]\n",
            " [ 9.21e+01  3.86e+02]\n",
            " [ 3.69e+01  4.00e+00]\n",
            " [ 4.29e+01  6.50e+01]\n",
            " [ 3.03e+01  4.00e+00]\n",
            " [-2.94e+01  7.00e+00]\n",
            " [ 3.47e+01  3.60e+01]\n",
            " [-1.57e+01  1.00e+00]\n",
            " [ 2.01e+01  3.00e+00]\n",
            " [ 1.92e+02  5.80e+01]\n",
            " [ 8.08e+01  8.30e+01]\n",
            " [ 1.44e+02  6.80e+01]\n",
            " [ 3.09e+01  2.90e+01]\n",
            " [ 2.87e+01  0.00e+00]\n",
            " [ 7.13e+01  1.80e+01]\n",
            " [ 2.44e+01  5.00e+00]\n",
            " [-2.05e+00  2.00e+00]\n",
            " [-8.28e+00  2.00e+00]\n",
            " [ 2.28e+02  1.70e+01]\n",
            " [ 9.67e+01  3.70e+01]\n",
            " [ 4.77e+01  1.30e+01]\n",
            " [-2.57e+01  0.00e+00]\n",
            " [ 3.11e+01  4.00e+00]\n",
            " [ 4.90e+01  1.91e+02]\n",
            " [ 1.12e+02  1.70e+01]\n",
            " [ 6.76e+01  1.19e+02]\n",
            " [ 4.49e+01  6.00e+00]\n",
            " [-5.53e+00  3.00e+00]\n",
            " [ 3.48e+01  8.00e+01]\n",
            " [ 2.45e+01  6.00e+01]\n",
            " [ 5.95e+01  9.00e+00]\n",
            " [ 6.23e+00  2.00e+01]\n",
            " [ 2.86e+00  6.00e+00]\n",
            " [ 1.56e+02  4.65e+02]\n",
            " [ 2.62e+01  0.00e+00]\n",
            " [ 4.43e+01  1.30e+01]\n",
            " [ 4.09e+01  1.13e+02]\n",
            " [ 1.57e+02  2.90e+01]\n",
            " [ 1.72e+02  1.26e+02]\n",
            " [ 2.50e+01  1.00e+00]\n",
            " [ 1.02e+00  8.00e+00]\n",
            " [ 1.26e+02  5.50e+01]\n",
            " [ 3.50e+01  2.90e+01]\n",
            " [ 5.08e+01  8.00e+00]\n",
            " [ 3.87e+01  3.40e+01]\n",
            " [ 1.18e+02  1.90e+01]\n",
            " [ 3.57e+01  1.30e+01]\n",
            " [ 2.09e+01  1.00e+01]\n",
            " [ 5.24e+01  2.74e+02]\n",
            " [ 4.11e+02  1.00e+00]\n",
            " [-4.73e+00  2.00e+01]\n",
            " [ 1.10e+02  1.80e+01]\n",
            " [ 3.10e+01  0.00e+00]\n",
            " [ 1.21e+02  2.10e+01]\n",
            " [ 4.77e+02  2.72e+02]\n",
            " [ 6.04e+00  2.50e+01]\n",
            " [ 6.94e+01  5.80e+01]\n",
            " [ 2.25e+02  6.10e+01]\n",
            " [ 3.51e+01  0.00e+00]\n",
            " [ 4.89e+01  2.70e+01]\n",
            " [ 1.94e+01  2.20e+01]\n",
            " [ 6.64e+01  9.00e+00]\n",
            " [ 6.39e+01  1.04e+02]\n",
            " [ 2.19e+01  1.10e+01]\n",
            " [ 3.06e+02  2.79e+02]\n",
            " [ 1.46e+02  2.52e+02]\n",
            " [ 5.10e+01  5.80e+01]\n",
            " [ 4.51e+01  3.80e+01]\n",
            " [ 9.82e+01  6.10e+01]\n",
            " [ 3.65e+01  0.00e+00]\n",
            " [-1.21e+02  5.00e+00]\n",
            " [ 1.43e+02  7.30e+01]\n",
            " [ 6.35e+01  3.40e+01]\n",
            " [ 4.51e+01  2.00e+00]\n",
            " [ 4.20e+02  8.41e+02]\n",
            " [ 4.15e+01  3.40e+01]\n",
            " [-5.32e+00  9.00e+00]\n",
            " [ 1.27e+02  5.00e+00]\n",
            " [ 3.73e+00  1.00e+00]\n",
            " [ 1.13e+02  3.80e+01]\n",
            " [ 4.44e+01  2.90e+01]\n",
            " [ 2.67e+00  5.00e+00]\n",
            " [ 1.32e+01  4.00e+00]\n",
            " [ 1.99e+01  9.00e+00]\n",
            " [ 2.58e+01  6.00e+00]\n",
            " [ 1.23e+02  8.10e+01]\n",
            " [ 3.33e+01  3.00e+00]\n",
            " [-1.51e+01  3.00e+00]\n",
            " [ 3.11e+01  1.40e+01]\n",
            " [ 4.56e+01  2.20e+01]\n",
            " [ 1.73e+02  1.36e+02]\n",
            " [ 1.14e+01  5.00e+00]\n",
            " [ 4.52e+01  9.30e+01]\n",
            " [ 8.22e+01  4.10e+01]\n",
            " [ 5.58e+01  0.00e+00]\n",
            " [ 3.10e+01  3.20e+01]\n",
            " [ 4.27e+02  9.03e+02]\n",
            " [ 3.10e+01  3.00e+00]\n",
            " [ 4.21e+01  3.30e+01]\n",
            " [-7.23e+00  0.00e+00]\n",
            " [ 3.86e+01  2.90e+01]\n",
            " [-6.18e+00  1.20e+01]\n",
            " [ 1.21e+02  1.21e+02]\n",
            " [ 6.69e+01  2.00e+01]\n",
            " [ 2.90e+02  0.00e+00]\n",
            " [ 7.67e+01  9.90e+01]\n",
            " [ 5.80e+01  9.10e+01]\n",
            " [ 7.41e+01  5.10e+01]\n",
            " [ 2.38e+01  3.50e+01]\n",
            " [-6.43e+00  0.00e+00]\n",
            " [ 1.35e+01  1.20e+01]\n",
            " [-2.58e+01  5.00e+00]\n",
            " [ 3.39e+00  2.30e+01]\n",
            " [ 1.95e+02  0.00e+00]\n",
            " [ 4.55e+01  6.00e+01]\n",
            " [ 4.06e+00  8.00e+00]\n",
            " [-2.19e+00  1.10e+01]\n",
            " [ 3.21e+01  5.00e+00]\n",
            " [ 1.42e+01  5.00e+00]\n",
            " [ 7.80e+01  3.30e+01]\n",
            " [-7.67e+00  7.00e+00]\n",
            " [ 3.14e+01  6.00e+00]\n",
            " [ 7.91e+01  6.30e+01]\n",
            " [ 6.69e+01  9.00e+00]\n",
            " [ 3.85e+01  1.20e+01]\n",
            " [ 4.70e+01  1.20e+01]\n",
            " [ 4.32e+02  5.35e+02]\n",
            " [ 9.71e+01  1.20e+01]\n",
            " [ 4.37e+01  5.00e+00]\n",
            " [ 6.54e+01  1.00e+00]\n",
            " [ 3.02e+00  0.00e+00]\n",
            " [ 7.32e+00  1.10e+01]\n",
            " [-4.86e+00  3.00e+00]\n",
            " [ 4.24e+01  1.90e+01]\n",
            " [ 3.18e+01  2.50e+01]\n",
            " [ 4.27e+01  5.10e+01]\n",
            " [ 3.73e+01  4.70e+01]\n",
            " [ 1.49e+02  9.90e+01]\n",
            " [ 1.31e+01  2.90e+01]\n",
            " [ 1.05e+02  5.39e+02]\n",
            " [ 9.22e+01  1.50e+01]\n",
            " [ 3.58e+01  1.50e+01]\n",
            " [ 3.04e+01  6.30e+01]\n",
            " [ 1.62e+01  1.10e+01]\n",
            " [ 7.60e+01  1.40e+01]\n",
            " [ 3.47e+01  0.00e+00]\n",
            " [ 4.27e+01  6.70e+01]\n",
            " [ 3.77e+01  1.50e+01]\n",
            " [-3.99e+00  8.00e+00]\n",
            " [ 1.48e+02  5.60e+01]\n",
            " [ 2.55e+02  9.30e+01]\n",
            " [ 1.07e+02  5.00e+01]\n",
            " [ 2.07e+01  2.70e+01]\n",
            " [ 4.09e+01  2.30e+01]\n",
            " [ 3.00e+01  1.30e+01]\n",
            " [ 1.99e+02  5.74e+02]\n",
            " [ 4.06e+01  7.20e+01]\n",
            " [ 5.37e+01  6.50e+01]\n",
            " [ 2.24e+01  3.00e+01]\n",
            " [ 3.89e+01  1.30e+01]\n",
            " [ 2.58e+02  1.91e+02]\n",
            " [ 5.18e+01  2.10e+01]\n",
            " [-1.23e+00  2.00e+00]\n",
            " [ 1.27e+02  2.81e+02]\n",
            " [ 2.23e+01  5.30e+01]\n",
            " [ 2.57e+02  1.09e+02]\n",
            " [ 1.88e+01  3.00e+00]\n",
            " [ 3.50e+01  2.80e+01]\n",
            " [ 6.68e+01  1.10e+01]\n",
            " [ 7.26e+00  7.00e+01]\n",
            " [ 1.40e+02  5.35e+02]\n",
            " [ 4.52e+01  6.00e+00]\n",
            " [ 3.12e+01  4.00e+00]\n",
            " [-3.04e+00  2.00e+00]\n",
            " [ 1.20e+01  4.00e+00]\n",
            " [ 2.10e+01  4.30e+01]\n",
            " [ 2.65e+01  5.00e+00]\n",
            " [ 2.95e+01  4.20e+01]\n",
            " [ 1.22e+02  1.44e+02]\n",
            " [ 2.80e+01  3.00e+00]\n",
            " [ 2.54e+01  8.00e+00]\n",
            " [-4.25e+01  1.00e+00]\n",
            " [-5.53e+01  4.00e+00]\n",
            " [ 3.64e+01  2.70e+01]\n",
            " [ 3.49e+01  9.00e+00]\n",
            " [ 1.62e+02  3.86e+02]\n",
            " [ 2.79e+01  1.00e+00]\n",
            " [ 2.78e+01  5.00e+00]\n",
            " [ 5.62e+01  2.60e+01]\n",
            " [ 4.29e+01  1.00e+00]\n",
            " [ 5.38e+01  1.26e+02]\n",
            " [ 2.31e+02  1.84e+02]\n",
            " [ 2.24e+01  7.00e+00]\n",
            " [ 2.75e+01  5.30e+01]\n",
            " [ 2.14e+01  3.00e+00]\n",
            " [ 7.76e+01  1.50e+01]\n",
            " [ 3.03e+00  3.00e+00]\n",
            " [ 1.92e+01  1.80e+01]\n",
            " [ 1.23e+01  3.30e+01]\n",
            " [ 8.35e+01  1.30e+01]\n",
            " [ 2.65e+01  4.60e+01]\n",
            " [ 2.79e+01  1.60e+01]\n",
            " [ 5.22e+01  8.80e+01]\n",
            " [ 1.91e+02  3.22e+02]\n",
            " [ 4.84e+01  8.00e+00]\n",
            " [ 2.07e+01  1.50e+01]\n",
            " [ 6.26e+01  1.60e+01]\n",
            " [ 1.06e+02  1.30e+01]\n",
            " [ 7.88e+01  2.02e+02]\n",
            " [ 3.88e+01  1.45e+02]\n",
            " [ 5.07e+01  9.90e+01]\n",
            " [-2.37e+01  5.00e+00]\n",
            " [ 4.25e+01  1.40e+01]\n",
            " [ 2.92e+01  9.00e+00]\n",
            " [ 1.17e+02  1.26e+02]\n",
            " [ 5.12e+01  1.10e+01]\n",
            " [ 5.14e+00  8.00e+00]\n",
            " [ 1.22e+01  1.00e+00]\n",
            " [ 4.36e+01  8.70e+01]\n",
            " [ 7.28e+01  0.00e+00]\n",
            " [-5.51e+00  0.00e+00]\n",
            " [ 6.85e+01  6.00e+00]\n",
            " [ 4.10e+01  5.80e+01]\n",
            " [ 1.56e+02  2.83e+02]\n",
            " [ 9.16e+02  2.60e+01]\n",
            " [ 2.76e+01  3.40e+01]\n",
            " [ 6.07e+00  3.00e+00]\n",
            " [ 7.84e+01  1.80e+01]\n",
            " [ 1.00e+03  3.49e+02]\n",
            " [ 5.11e+00  0.00e+00]\n",
            " [ 1.16e+02  1.80e+01]\n",
            " [ 6.06e+01  1.30e+01]\n",
            " [ 1.94e+01  2.10e+01]\n",
            " [ 6.14e+01  7.20e+01]\n",
            " [ 3.73e+02  1.25e+02]\n",
            " [ 6.02e+01  9.70e+01]\n",
            " [ 5.01e+01  1.30e+01]\n",
            " [-5.25e+00  1.00e+01]\n",
            " [ 1.29e+01  5.00e+00]\n",
            " [ 1.31e+02  3.60e+02]\n",
            " [ 8.14e+01  5.60e+01]\n",
            " [ 7.38e+01  6.00e+00]\n",
            " [ 3.31e+01  3.80e+01]\n",
            " [ 1.59e+02  1.52e+02]\n",
            " [ 1.22e+02  1.64e+02]\n",
            " [ 2.93e+01  0.00e+00]\n",
            " [ 6.12e+01  4.40e+01]\n",
            " [ 2.00e+01  4.00e+00]\n",
            " [ 5.40e+01  4.00e+00]\n",
            " [ 4.43e+01  5.50e+01]\n",
            " [ 2.17e+02  4.75e+02]\n",
            " [-1.44e+01  1.60e+01]\n",
            " [ 3.25e+02  3.70e+02]\n",
            " [ 4.05e+01  1.30e+01]\n",
            " [ 7.44e+01  1.83e+02]\n",
            " [ 1.63e+02  8.30e+01]\n",
            " [ 1.63e+01  1.20e+01]\n",
            " [ 3.01e+02  1.41e+02]\n",
            " [ 1.02e+02  3.80e+01]\n",
            " [ 7.12e+01  5.00e+01]\n",
            " [ 1.21e+02  8.60e+01]\n",
            " [ 2.47e+01  2.00e+00]\n",
            " [ 1.19e+02  5.40e+01]\n",
            " [ 3.53e+01  2.40e+01]\n",
            " [ 3.32e+01  3.30e+01]\n",
            " [ 1.72e+01  1.00e+01]\n",
            " [ 6.35e+01  1.20e+01]\n",
            " [ 1.68e+01  3.70e+01]\n",
            " [-2.45e+01  4.00e+00]\n",
            " [-8.17e+00  1.20e+01]\n",
            " [ 5.10e+01  2.40e+01]\n",
            " [ 1.80e+02  2.00e+00]\n",
            " [ 5.37e+01  6.10e+01]\n",
            " [ 9.11e+01  6.90e+01]\n",
            " [ 3.25e+02  1.52e+02]\n",
            " [ 1.62e+02  1.81e+02]\n",
            " [ 1.24e+02  3.00e+01]\n",
            " [ 2.57e+01  2.00e+00]\n",
            " [-3.97e+00  6.00e+00]\n",
            " [ 1.01e+02  2.12e+02]\n",
            " [ 4.28e+01  1.30e+01]\n",
            " [ 2.23e-01  6.00e+00]\n",
            " [ 1.86e+01  2.40e+01]\n",
            " [ 5.35e+00  3.00e+00]\n",
            " [ 1.06e+02  1.30e+01]\n",
            " [ 7.71e+01  1.90e+01]\n",
            " [ 8.82e+01  6.00e+00]\n",
            " [ 7.63e+01  4.20e+01]\n",
            " [ 3.27e+01  3.10e+01]\n",
            " [ 2.88e-01  1.10e+01]\n",
            " [ 1.47e+01  1.00e+00]\n",
            " [ 8.04e+01  2.20e+01]\n",
            " [ 2.94e+01  2.20e+01]\n",
            " [ 5.95e+01  5.40e+01]\n",
            " [ 4.14e+01  4.40e+01]\n",
            " [ 6.50e+01  4.00e+00]\n",
            " [ 1.87e+01  2.60e+01]\n",
            " [ 6.74e+01  5.00e+00]\n",
            " [ 1.59e+01  1.60e+01]\n",
            " [ 1.50e+00  1.00e+00]\n",
            " [ 1.67e+01  4.00e+00]\n",
            " [ 3.30e+01  1.00e+01]\n",
            " [ 3.01e+02  1.00e+00]\n",
            " [ 2.28e+01  1.00e+01]\n",
            " [ 7.40e+01  1.40e+01]\n",
            " [ 1.97e+01  2.00e+01]\n",
            " [ 3.48e+00  2.00e+00]\n",
            " [ 1.44e+01  1.90e+01]\n",
            " [ 2.89e+01  1.30e+01]\n",
            " [ 8.75e+01  5.60e+01]\n",
            " [ 1.40e+02  5.00e+01]\n",
            " [ 7.99e+01  2.40e+01]\n",
            " [ 3.25e+01  4.60e+01]\n",
            " [-3.00e+00  4.00e+00]\n",
            " [ 3.64e+01  2.80e+01]\n",
            " [ 8.58e+01  1.05e+02]\n",
            " [ 3.46e+01  2.80e+01]\n",
            " [ 8.40e+00  0.00e+00]\n",
            " [ 5.69e+01  1.95e+02]\n",
            " [ 5.12e+01  2.40e+01]\n",
            " [ 2.00e+02  1.82e+02]\n",
            " [-1.09e+01  2.00e+00]\n",
            " [ 7.97e+01  0.00e+00]\n",
            " [ 1.23e+01  1.00e+01]\n",
            " [ 2.07e+01  5.00e+00]\n",
            " [ 6.59e+01  1.20e+01]\n",
            " [ 1.99e+02  5.00e+02]\n",
            " [ 2.58e+01  1.20e+01]\n",
            " [-7.20e+00  1.00e+01]\n",
            " [ 2.95e+01  1.40e+01]\n",
            " [ 1.37e+02  3.31e+02]\n",
            " [-2.23e+01  1.00e+00]\n",
            " [-3.06e+01  6.00e+00]\n",
            " [ 1.16e+02  6.30e+01]\n",
            " [ 5.09e+01  1.50e+01]\n",
            " [ 3.05e+02  5.13e+02]\n",
            " [ 5.07e+01  4.70e+01]\n",
            " [ 1.95e+01  1.00e+00]\n",
            " [ 6.54e+01  9.50e+01]\n",
            " [ 3.39e+01  0.00e+00]\n",
            " [ 6.67e+00  3.00e+00]\n",
            " [ 1.30e+02  5.20e+01]\n",
            " [ 3.16e+01  0.00e+00]\n",
            " [ 3.99e+02  2.09e+02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Computing R2 value"
      ],
      "metadata": {
        "id": "_jD7KLPDSMKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLkVMrQrSOvt",
        "outputId": "82ed86b5-102f-4c2f-e38c-3dbc0d1d38b5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.20369752906674887"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Applying K-Fold cross validation"
      ],
      "metadata": {
        "id": "CSucf8rLEh7S"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYbfiITD8ZAz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d4e0c10-d8f6-445a-f1b4-1df726e618a3"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "accuracies = cross_val_score(estimator = regressor, X = X_train, y = y_train, cv = 10)\n",
        "print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
        "print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 18.92 %\n",
            "Standard Deviation: 48.86 %\n"
          ]
        }
      ]
    }
  ]
}