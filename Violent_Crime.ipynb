{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Violent Crime.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Import libraries and data"
      ],
      "metadata": {
        "id": "QRo5Hl7k8Hjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "4glNq_DC8O3B"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv('2019 income data by county.csv', encoding='latin-1', thousands=',')\n",
        "df2 = pd.read_csv('co-est2019-alldata.csv', encoding='latin-1', thousands=',')\n",
        "df3 = pd.read_csv('Table_10_Offenses_Known_to_Law_Enforcement_by_State_by_Metropolitan_and_Nonmetropolitan_Counties_2019.csv', thousands=',')"
      ],
      "metadata": {
        "id": "9y3uTlr48PxJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data cleaning\n",
        "Some data cleaning done in Excel, including use of VLookup."
      ],
      "metadata": {
        "id": "UkeTRAzmwiYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df1[df1.LineCode == 3]\n",
        "df1['State1'] = df1['State1'].str.strip()\n",
        "df1['County'] = df1['County'].str.strip()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7wEp1ydteL1",
        "outputId": "748ecd56-b143-4ac5-bb68-07768f7ba34e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Join data sets"
      ],
      "metadata": {
        "id": "PYbV58t7-Bqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import reduce\n",
        "data_frames = [df3, df1, df2]\n",
        "data = reduce(lambda  left,right: pd.merge(left,right,on=['County', 'State1'],\n",
        "                                            how='outer', validate = 'many_to_many'), data_frames)"
      ],
      "metadata": {
        "id": "lOqANuOC-JKp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.rename(columns={'Violent\\ncrime': 'Violent crime'})"
      ],
      "metadata": {
        "id": "yS2cjHe6ODJe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Removing missing data"
      ],
      "metadata": {
        "id": "Q5KHAGtlBm1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.dropna(subset=['2019', 'Metro', 'POPESTIMATE2019', 'Violent crime'])"
      ],
      "metadata": {
        "id": "4889nGiHBpkX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compression_opts = dict(method='zip',\n",
        "#                       archive_name='out.csv')  \n",
        "#data.to_csv('out.zip', index=False,\n",
        "#          compression=compression_opts)"
      ],
      "metadata": {
        "id": "Y_aIU-PuFe9g"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create X and y variables"
      ],
      "metadata": {
        "id": "6Shc4Tg_w_Gj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data[['2019', 'POPESTIMATE2019', 'Metro']].values\n",
        "X = np.asarray(X).astype(np.float32)\n",
        "y = data['Violent crime'].values"
      ],
      "metadata": {
        "id": "YZbEY-7vxE-r"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Split into training and test set"
      ],
      "metadata": {
        "id": "IwW2hjjvIKOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
      ],
      "metadata": {
        "id": "CmtWD1HUIMno"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Feature Scaling"
      ],
      "metadata": {
        "id": "54RyVSZdIOqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train[:, :-1] = sc.fit_transform(X_train[:, :-1])\n",
        "X_test[:, :-1] = sc.transform(X_test[:, :-1])"
      ],
      "metadata": {
        "id": "JhXz5wBtIPzw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Regression models"
      ],
      "metadata": {
        "id": "yrbXTfcRIfk3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Multiple linear regression"
      ],
      "metadata": {
        "id": "xF4HTTlvSchP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW_RFGAAIiPX",
        "outputId": "0703d9c6-d0b7-421d-a44e-8293a89194f0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Support vector regression"
      ],
      "metadata": {
        "id": "bTdj7a2eSg7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "regressor = SVR(kernel = 'rbf')\n",
        "regressor.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMfLkGUZSo1n",
        "outputId": "8eb20092-1826-45d6-bfd2-1fd010d9d741"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVR()"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Random forest regression"
      ],
      "metadata": {
        "id": "XAktpqyjS0PP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "regressor = RandomForestRegressor(n_estimators = 100, random_state = 0)\n",
        "regressor.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuwpPOdpS5uG",
        "outputId": "2d19646f-82d6-4380-849e-787564a4c12e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###XGBoost"
      ],
      "metadata": {
        "id": "taEWCemgTQLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "regressor = XGBRegressor(objective='reg:squarederror')\n",
        "regressor.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yPV-tobTScd",
        "outputId": "3a9e6faa-de8b-4e24-d7e1-628e284fdcce"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(objective='reg:squarederror')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Artificial neural network"
      ],
      "metadata": {
        "id": "saCVZyX2UJgA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann = tf.keras.models.Sequential()\n",
        "ann.add(tf.keras.layers.Dense(units=9, input_dim=3, activation='relu'))\n",
        "ann.add(tf.keras.layers.Dense(units=9, activation='relu'))\n",
        "ann.add(tf.keras.layers.Dense(units=9, activation='tanh'))\n",
        "ann.add(tf.keras.layers.Dense(units=1))\n",
        "ann.compile(loss='mean_squared_error', optimizer='adam', metrics = ['Accuracy'])"
      ],
      "metadata": {
        "id": "jW41iJC1UNI2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann.fit(X_train, y_train, batch_size = 32, epochs = 150)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_W8QT80Vo8m",
        "outputId": "e5fe7cf0-62e7-4b1e-bfe3-0fa4226e3148"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "53/53 [==============================] - 1s 4ms/step - loss: 116845.6172 - Accuracy: 0.0601\n",
            "Epoch 2/150\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 116768.0547 - Accuracy: 0.0613\n",
            "Epoch 3/150\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 116694.0391 - Accuracy: 0.0506\n",
            "Epoch 4/150\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 116599.0703 - Accuracy: 0.0321\n",
            "Epoch 5/150\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 116498.3594 - Accuracy: 0.0310\n",
            "Epoch 6/150\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 116404.8125 - Accuracy: 0.0310\n",
            "Epoch 7/150\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 116320.4375 - Accuracy: 0.0310\n",
            "Epoch 8/150\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 116237.7344 - Accuracy: 0.0310\n",
            "Epoch 9/150\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 116155.6484 - Accuracy: 0.0310\n",
            "Epoch 10/150\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 116076.1250 - Accuracy: 0.0310\n",
            "Epoch 11/150\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 116000.0547 - Accuracy: 0.0310\n",
            "Epoch 12/150\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 115925.6641 - Accuracy: 0.0310\n",
            "Epoch 13/150\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 115854.0859 - Accuracy: 0.0310\n",
            "Epoch 14/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 115788.1328 - Accuracy: 0.0310\n",
            "Epoch 15/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 115721.8594 - Accuracy: 0.0310\n",
            "Epoch 16/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 115657.2578 - Accuracy: 0.0310\n",
            "Epoch 17/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 115592.8281 - Accuracy: 0.0310\n",
            "Epoch 18/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 115529.0703 - Accuracy: 0.0310\n",
            "Epoch 19/150\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 115467.8281 - Accuracy: 0.0310\n",
            "Epoch 20/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 115408.3828 - Accuracy: 0.0310\n",
            "Epoch 21/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 115349.5312 - Accuracy: 0.0310\n",
            "Epoch 22/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 115290.8594 - Accuracy: 0.0310\n",
            "Epoch 23/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 115235.1328 - Accuracy: 0.0310\n",
            "Epoch 24/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 115177.5781 - Accuracy: 0.0310\n",
            "Epoch 25/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 115121.3359 - Accuracy: 0.0310\n",
            "Epoch 26/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 115066.6562 - Accuracy: 0.0310\n",
            "Epoch 27/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 115012.2578 - Accuracy: 0.0310\n",
            "Epoch 28/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 114957.9844 - Accuracy: 0.0310\n",
            "Epoch 29/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 114905.4219 - Accuracy: 0.0310\n",
            "Epoch 30/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 114852.0938 - Accuracy: 0.0310\n",
            "Epoch 31/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 114800.5391 - Accuracy: 0.0310\n",
            "Epoch 32/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 114750.3125 - Accuracy: 0.0310\n",
            "Epoch 33/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 114699.1016 - Accuracy: 0.0310\n",
            "Epoch 34/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 114649.5547 - Accuracy: 0.0310\n",
            "Epoch 35/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 114600.3984 - Accuracy: 0.0310\n",
            "Epoch 36/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 114551.3594 - Accuracy: 0.0310\n",
            "Epoch 37/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 114503.7734 - Accuracy: 0.0310\n",
            "Epoch 38/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 114456.9297 - Accuracy: 0.0310\n",
            "Epoch 39/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 114408.9297 - Accuracy: 0.0310\n",
            "Epoch 40/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 114362.4219 - Accuracy: 0.0310\n",
            "Epoch 41/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 114316.4844 - Accuracy: 0.0310\n",
            "Epoch 42/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 114270.1250 - Accuracy: 0.0310\n",
            "Epoch 43/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 114224.1328 - Accuracy: 0.0310\n",
            "Epoch 44/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 114178.0156 - Accuracy: 0.0310\n",
            "Epoch 45/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 114132.4609 - Accuracy: 0.0310\n",
            "Epoch 46/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 114084.8750 - Accuracy: 0.0310\n",
            "Epoch 47/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 114038.1406 - Accuracy: 0.0310\n",
            "Epoch 48/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113990.3203 - Accuracy: 0.0310\n",
            "Epoch 49/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113942.9922 - Accuracy: 0.0310\n",
            "Epoch 50/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113896.5547 - Accuracy: 0.0310\n",
            "Epoch 51/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113850.1406 - Accuracy: 0.0310\n",
            "Epoch 52/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113803.8125 - Accuracy: 0.0310\n",
            "Epoch 53/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113758.2734 - Accuracy: 0.0310\n",
            "Epoch 54/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113710.5703 - Accuracy: 0.0310\n",
            "Epoch 55/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113665.1406 - Accuracy: 0.0310\n",
            "Epoch 56/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113618.0078 - Accuracy: 0.0310\n",
            "Epoch 57/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113570.8125 - Accuracy: 0.0310\n",
            "Epoch 58/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113525.6641 - Accuracy: 0.0310\n",
            "Epoch 59/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113477.3125 - Accuracy: 0.0310\n",
            "Epoch 60/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113429.1875 - Accuracy: 0.0310\n",
            "Epoch 61/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113382.3047 - Accuracy: 0.0310\n",
            "Epoch 62/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113338.1641 - Accuracy: 0.0310\n",
            "Epoch 63/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113289.7656 - Accuracy: 0.0310\n",
            "Epoch 64/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113244.2969 - Accuracy: 0.0310\n",
            "Epoch 65/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113197.3203 - Accuracy: 0.0310\n",
            "Epoch 66/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113153.0078 - Accuracy: 0.0310\n",
            "Epoch 67/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113107.2344 - Accuracy: 0.0310\n",
            "Epoch 68/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113063.0469 - Accuracy: 0.0310\n",
            "Epoch 69/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 113018.7031 - Accuracy: 0.0315\n",
            "Epoch 70/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112976.0547 - Accuracy: 0.0315\n",
            "Epoch 71/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112931.7266 - Accuracy: 0.0310\n",
            "Epoch 72/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112889.4609 - Accuracy: 0.0333\n",
            "Epoch 73/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112847.3125 - Accuracy: 0.0339\n",
            "Epoch 74/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112804.6875 - Accuracy: 0.0333\n",
            "Epoch 75/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112762.5781 - Accuracy: 0.0333\n",
            "Epoch 76/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112721.7891 - Accuracy: 0.0321\n",
            "Epoch 77/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112681.0859 - Accuracy: 0.0345\n",
            "Epoch 78/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112638.4609 - Accuracy: 0.0315\n",
            "Epoch 79/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112597.6016 - Accuracy: 0.0327\n",
            "Epoch 80/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112556.9219 - Accuracy: 0.0310\n",
            "Epoch 81/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112516.7891 - Accuracy: 0.0304\n",
            "Epoch 82/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112478.0703 - Accuracy: 0.0333\n",
            "Epoch 83/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112437.1719 - Accuracy: 0.0304\n",
            "Epoch 84/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112396.7422 - Accuracy: 0.0304\n",
            "Epoch 85/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112357.2031 - Accuracy: 0.0310\n",
            "Epoch 86/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112317.7031 - Accuracy: 0.0310\n",
            "Epoch 87/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112277.1719 - Accuracy: 0.0304\n",
            "Epoch 88/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112238.0156 - Accuracy: 0.0315\n",
            "Epoch 89/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112200.4922 - Accuracy: 0.0310\n",
            "Epoch 90/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112161.0781 - Accuracy: 0.0304\n",
            "Epoch 91/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112121.6094 - Accuracy: 0.0304\n",
            "Epoch 92/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112083.3203 - Accuracy: 0.0304\n",
            "Epoch 93/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 112047.6875 - Accuracy: 0.0315\n",
            "Epoch 94/150\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 112007.2188 - Accuracy: 0.0310\n",
            "Epoch 95/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111969.1719 - Accuracy: 0.0310\n",
            "Epoch 96/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111931.2266 - Accuracy: 0.0310\n",
            "Epoch 97/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111893.2891 - Accuracy: 0.0310\n",
            "Epoch 98/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111856.6406 - Accuracy: 0.0310\n",
            "Epoch 99/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111818.6875 - Accuracy: 0.0310\n",
            "Epoch 100/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111780.6094 - Accuracy: 0.0310\n",
            "Epoch 101/150\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 111745.0547 - Accuracy: 0.0310\n",
            "Epoch 102/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111707.2344 - Accuracy: 0.0310\n",
            "Epoch 103/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111671.9062 - Accuracy: 0.0298\n",
            "Epoch 104/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111638.1406 - Accuracy: 0.0310\n",
            "Epoch 105/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111600.4375 - Accuracy: 0.0304\n",
            "Epoch 106/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111567.1641 - Accuracy: 0.0304\n",
            "Epoch 107/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111529.7109 - Accuracy: 0.0321\n",
            "Epoch 108/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111492.2188 - Accuracy: 0.0298\n",
            "Epoch 109/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111456.7734 - Accuracy: 0.0310\n",
            "Epoch 110/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111423.7891 - Accuracy: 0.0310\n",
            "Epoch 111/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111387.9453 - Accuracy: 0.0310\n",
            "Epoch 112/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111352.7344 - Accuracy: 0.0310\n",
            "Epoch 113/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111318.2344 - Accuracy: 0.0310\n",
            "Epoch 114/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111283.1250 - Accuracy: 0.0304\n",
            "Epoch 115/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111250.0078 - Accuracy: 0.0310\n",
            "Epoch 116/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111215.6953 - Accuracy: 0.0304\n",
            "Epoch 117/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111180.1719 - Accuracy: 0.0310\n",
            "Epoch 118/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111147.5156 - Accuracy: 0.0304\n",
            "Epoch 119/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111112.2266 - Accuracy: 0.0310\n",
            "Epoch 120/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111080.6406 - Accuracy: 0.0304\n",
            "Epoch 121/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111046.0859 - Accuracy: 0.0304\n",
            "Epoch 122/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 111013.4453 - Accuracy: 0.0321\n",
            "Epoch 123/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110979.4375 - Accuracy: 0.0304\n",
            "Epoch 124/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110948.5078 - Accuracy: 0.0310\n",
            "Epoch 125/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110913.5234 - Accuracy: 0.0315\n",
            "Epoch 126/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110880.4844 - Accuracy: 0.0304\n",
            "Epoch 127/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110850.3594 - Accuracy: 0.0304\n",
            "Epoch 128/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110816.3359 - Accuracy: 0.0310\n",
            "Epoch 129/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110782.9922 - Accuracy: 0.0310\n",
            "Epoch 130/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110751.9531 - Accuracy: 0.0304\n",
            "Epoch 131/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110720.5547 - Accuracy: 0.0304\n",
            "Epoch 132/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110686.9922 - Accuracy: 0.0304\n",
            "Epoch 133/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110657.5156 - Accuracy: 0.0298\n",
            "Epoch 134/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110625.0312 - Accuracy: 0.0310\n",
            "Epoch 135/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110592.1250 - Accuracy: 0.0310\n",
            "Epoch 136/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110563.1172 - Accuracy: 0.0321\n",
            "Epoch 137/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110531.3203 - Accuracy: 0.0310\n",
            "Epoch 138/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110500.0156 - Accuracy: 0.0304\n",
            "Epoch 139/150\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 110470.4219 - Accuracy: 0.0321\n",
            "Epoch 140/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110438.6953 - Accuracy: 0.0304\n",
            "Epoch 141/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110409.3125 - Accuracy: 0.0310\n",
            "Epoch 142/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110379.4844 - Accuracy: 0.0310\n",
            "Epoch 143/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110349.2578 - Accuracy: 0.0310\n",
            "Epoch 144/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110321.6875 - Accuracy: 0.0304\n",
            "Epoch 145/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110290.3125 - Accuracy: 0.0310\n",
            "Epoch 146/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110259.7422 - Accuracy: 0.0315\n",
            "Epoch 147/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110235.1719 - Accuracy: 0.0304\n",
            "Epoch 148/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110203.0938 - Accuracy: 0.0304\n",
            "Epoch 149/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110174.9531 - Accuracy: 0.0310\n",
            "Epoch 150/150\n",
            "53/53 [==============================] - 0s 2ms/step - loss: 110148.9062 - Accuracy: 0.0310\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2d08305b50>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Predicting test set results"
      ],
      "metadata": {
        "id": "G3_LqjYuRFhm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = regressor.predict(X_test)\n",
        "np.set_printoptions(precision=2)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RU6iBi_GRlUu",
        "outputId": "5429b13f-60a6-47fb-fcfd-473190df19bb"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3.49e+01  8.40e+01]\n",
            " [ 1.09e+01  2.60e+01]\n",
            " [ 2.18e+01  1.20e+01]\n",
            " [ 3.24e+01  4.40e+01]\n",
            " [-1.82e+00  1.00e+01]\n",
            " [ 3.42e+01  3.70e+01]\n",
            " [ 2.10e+00  2.00e+00]\n",
            " [ 2.25e+01  3.30e+01]\n",
            " [ 1.58e+01  1.30e+01]\n",
            " [ 3.27e+02  8.70e+01]\n",
            " [ 4.89e+01  4.80e+01]\n",
            " [ 1.04e+02  3.20e+01]\n",
            " [ 2.12e+01  6.00e+00]\n",
            " [ 1.86e+01  2.00e+01]\n",
            " [ 2.08e+00  0.00e+00]\n",
            " [ 1.55e+02  1.26e+02]\n",
            " [ 1.13e+02  3.90e+01]\n",
            " [ 9.96e+01  5.50e+01]\n",
            " [ 3.81e+01  2.80e+01]\n",
            " [ 1.22e+02  2.92e+02]\n",
            " [ 3.22e+01  4.00e+00]\n",
            " [ 7.30e+01  1.21e+02]\n",
            " [ 1.54e+01  2.00e+01]\n",
            " [ 4.91e+00  1.00e+00]\n",
            " [ 1.20e+01  1.80e+01]\n",
            " [-3.44e+01  1.30e+01]\n",
            " [ 8.26e+01  4.00e+00]\n",
            " [ 3.11e+01  2.20e+01]\n",
            " [ 1.20e+02  5.10e+01]\n",
            " [ 2.94e+01  2.30e+01]\n",
            " [-1.10e+01  1.50e+01]\n",
            " [ 2.29e+02  9.30e+01]\n",
            " [ 3.21e+01  4.20e+01]\n",
            " [ 4.52e+01  1.30e+01]\n",
            " [ 4.80e+01  3.80e+01]\n",
            " [ 3.94e+01  4.00e+00]\n",
            " [ 3.40e+01  2.50e+01]\n",
            " [ 2.86e+01  1.10e+01]\n",
            " [ 1.50e+01  1.00e+00]\n",
            " [ 4.51e+00  5.00e+00]\n",
            " [ 9.04e+00  0.00e+00]\n",
            " [ 1.21e+02  2.81e+02]\n",
            " [ 8.82e+01  1.19e+02]\n",
            " [ 5.52e+02  3.00e+00]\n",
            " [ 3.49e+01  8.00e+00]\n",
            " [-4.32e+00  0.00e+00]\n",
            " [ 2.77e+01  5.00e+00]\n",
            " [ 1.67e+01  5.00e+00]\n",
            " [ 7.50e+01  6.00e+00]\n",
            " [ 9.18e+01  2.00e+01]\n",
            " [ 1.09e+02  3.70e+01]\n",
            " [ 4.60e+01  7.00e+00]\n",
            " [ 6.19e+01  4.30e+01]\n",
            " [ 1.43e+00  3.00e+00]\n",
            " [ 3.42e+01  3.00e+00]\n",
            " [ 1.06e+01  4.00e+00]\n",
            " [ 1.36e+01  1.00e+01]\n",
            " [ 2.35e+01  0.00e+00]\n",
            " [-2.43e+00  7.00e+00]\n",
            " [ 2.21e+01  1.30e+01]\n",
            " [ 1.78e+01  0.00e+00]\n",
            " [ 3.89e+01  9.00e+00]\n",
            " [ 1.76e+02  6.00e+01]\n",
            " [-1.31e+01  4.00e+00]\n",
            " [ 2.45e-01  2.00e+00]\n",
            " [ 1.00e+02  1.70e+01]\n",
            " [ 1.72e+01  7.00e+00]\n",
            " [ 5.89e+01  8.70e+01]\n",
            " [ 2.40e+01  1.00e+00]\n",
            " [ 3.08e+01  3.00e+00]\n",
            " [ 1.75e+01  6.00e+00]\n",
            " [ 7.01e+01  3.00e+00]\n",
            " [ 2.97e+01  1.00e+01]\n",
            " [ 1.01e+03  1.50e+03]\n",
            " [ 7.57e+01  6.30e+01]\n",
            " [ 3.93e+01  7.50e+01]\n",
            " [ 4.67e+00  8.00e+00]\n",
            " [ 8.30e+00  1.20e+01]\n",
            " [ 1.34e+01  6.00e+00]\n",
            " [ 5.74e+01  3.40e+01]\n",
            " [ 3.57e+01  3.00e+00]\n",
            " [ 1.22e+01  5.00e+00]\n",
            " [ 1.28e+02  3.31e+02]\n",
            " [ 2.65e+02  0.00e+00]\n",
            " [ 2.68e+00  1.30e+01]\n",
            " [ 1.56e+01  6.00e+00]\n",
            " [ 1.35e+02  2.11e+02]\n",
            " [ 9.45e+01  1.54e+02]\n",
            " [ 9.65e+01  0.00e+00]\n",
            " [ 9.13e+00  2.50e+01]\n",
            " [ 2.45e+01  1.00e+00]\n",
            " [ 6.76e+01  3.10e+02]\n",
            " [ 2.72e+02  5.13e+02]\n",
            " [ 1.22e+02  4.57e+02]\n",
            " [ 1.23e+03  5.35e+03]\n",
            " [ 1.00e+02  1.87e+02]\n",
            " [ 5.57e+01  2.70e+01]\n",
            " [ 1.61e+02  6.50e+01]\n",
            " [ 3.12e+01  2.00e+00]\n",
            " [ 2.96e+01  2.90e+01]\n",
            " [ 1.14e+02  5.60e+01]\n",
            " [ 1.16e+01  0.00e+00]\n",
            " [ 2.59e+01  1.60e+01]\n",
            " [ 5.37e+01  1.49e+02]\n",
            " [ 5.19e+01  9.10e+01]\n",
            " [ 1.58e+01  1.90e+01]\n",
            " [-1.10e+01  2.00e+00]\n",
            " [ 8.98e+00  0.00e+00]\n",
            " [ 1.03e+01  9.00e+00]\n",
            " [ 4.46e+01  3.00e+01]\n",
            " [ 2.98e+00  1.30e+01]\n",
            " [ 2.34e+01  2.10e+01]\n",
            " [ 4.58e+01  1.50e+01]\n",
            " [ 4.75e+01  0.00e+00]\n",
            " [ 3.77e+01  7.60e+01]\n",
            " [ 4.36e+01  3.00e+01]\n",
            " [ 1.76e+01  1.00e+00]\n",
            " [ 1.01e+02  3.22e+02]\n",
            " [ 1.22e+02  1.23e+02]\n",
            " [ 1.96e+02  2.80e+02]\n",
            " [ 8.95e+01  1.76e+02]\n",
            " [ 5.50e+01  6.20e+01]\n",
            " [ 1.15e+01  2.00e+00]\n",
            " [ 3.17e+01  1.38e+02]\n",
            " [ 3.69e+01  1.00e+00]\n",
            " [ 3.22e+01  2.80e+01]\n",
            " [-1.98e+01  8.00e+00]\n",
            " [ 1.22e+02  8.30e+01]\n",
            " [ 2.22e+01  6.10e+01]\n",
            " [ 1.65e+00  1.10e+01]\n",
            " [ 4.17e+01  1.70e+01]\n",
            " [ 9.51e+01  5.00e+01]\n",
            " [ 1.19e+01  6.00e+00]\n",
            " [ 2.31e+01  5.00e+00]\n",
            " [ 2.03e+01  3.00e+00]\n",
            " [ 3.07e+01  2.00e+00]\n",
            " [ 7.30e+01  5.60e+01]\n",
            " [ 1.27e+02  8.64e+02]\n",
            " [ 7.78e+01  4.30e+01]\n",
            " [ 7.10e+01  6.30e+01]\n",
            " [ 5.25e+01  3.30e+01]\n",
            " [ 1.33e+02  9.90e+01]\n",
            " [-1.62e+01  6.00e+00]\n",
            " [ 9.45e+01  2.80e+01]\n",
            " [ 2.90e+01  1.50e+01]\n",
            " [ 4.05e+01  8.70e+01]\n",
            " [ 1.15e+02  3.50e+01]\n",
            " [ 1.78e+01  7.00e+00]\n",
            " [ 8.93e+00  4.00e+00]\n",
            " [ 2.21e+01  2.10e+01]\n",
            " [ 1.91e+01  2.20e+01]\n",
            " [ 9.53e+01  5.60e+01]\n",
            " [ 6.90e+01  4.80e+01]\n",
            " [ 3.93e+01  2.60e+01]\n",
            " [ 2.83e+01  4.60e+01]\n",
            " [-9.45e+00  2.90e+01]\n",
            " [ 4.27e+01  4.90e+01]\n",
            " [ 1.40e+01  1.00e+01]\n",
            " [ 7.33e+00  8.00e+00]\n",
            " [ 2.92e+01  1.80e+01]\n",
            " [ 1.77e+02  5.00e+02]\n",
            " [ 2.16e+01  1.20e+01]\n",
            " [ 2.66e+01  3.00e+00]\n",
            " [ 3.42e+01  6.40e+01]\n",
            " [ 8.99e+01  3.00e+00]\n",
            " [ 3.59e+01  2.60e+01]\n",
            " [ 3.96e+01  2.90e+01]\n",
            " [-5.83e+00  1.90e+01]\n",
            " [ 2.87e+01  9.00e+00]\n",
            " [ 4.44e+01  1.00e+00]\n",
            " [ 3.30e+01  1.20e+01]\n",
            " [ 1.53e+02  1.11e+02]\n",
            " [-1.88e+00  2.00e+00]\n",
            " [ 2.46e+01  0.00e+00]\n",
            " [ 7.99e+00  3.00e+00]\n",
            " [ 7.49e+00  4.00e+00]\n",
            " [ 3.49e+01  2.20e+01]\n",
            " [ 2.53e+01  9.00e+00]\n",
            " [ 6.48e+01  2.50e+01]\n",
            " [ 1.69e+01  4.00e+00]\n",
            " [ 1.98e+01  9.00e+00]\n",
            " [ 3.78e+02  8.41e+02]\n",
            " [ 1.04e+01  5.00e+00]\n",
            " [ 1.93e+01  4.80e+01]\n",
            " [ 1.66e+01  1.50e+01]\n",
            " [ 4.90e+01  1.70e+01]\n",
            " [ 7.14e+01  2.00e+01]\n",
            " [ 2.18e+01  5.30e+01]\n",
            " [ 2.17e+01  2.50e+01]\n",
            " [-9.13e+00  3.30e+01]\n",
            " [ 5.37e+00  0.00e+00]\n",
            " [ 4.64e+02  6.60e+01]\n",
            " [ 4.36e+01  5.50e+01]\n",
            " [ 3.42e+01  4.00e+01]\n",
            " [ 2.38e+01  1.00e+00]\n",
            " [ 8.25e+01  5.50e+01]\n",
            " [ 5.48e+01  1.60e+01]\n",
            " [ 2.65e+01  6.00e+00]\n",
            " [ 1.45e+02  7.40e+01]\n",
            " [ 1.86e+02  1.04e+03]\n",
            " [ 1.04e+02  6.10e+01]\n",
            " [ 6.46e+01  2.20e+01]\n",
            " [ 8.23e+01  1.20e+02]\n",
            " [ 6.83e+01  1.00e+01]\n",
            " [ 4.87e+01  4.00e+00]\n",
            " [ 2.14e+01  7.00e+00]\n",
            " [ 9.14e+01  3.80e+01]\n",
            " [ 7.34e+01  5.60e+01]\n",
            " [ 3.06e+01  3.00e+01]\n",
            " [ 7.56e+01  1.60e+02]\n",
            " [ 2.72e+02  1.95e+02]\n",
            " [ 3.27e+01  0.00e+00]\n",
            " [ 1.06e+01  1.00e+01]\n",
            " [ 2.64e+01  3.00e+00]\n",
            " [ 7.09e+01  8.00e+00]\n",
            " [ 4.71e+01  3.90e+01]\n",
            " [ 9.70e+01  1.10e+02]\n",
            " [ 9.97e+01  2.18e+02]\n",
            " [ 1.26e+01  3.10e+01]\n",
            " [ 3.11e+01  2.60e+01]\n",
            " [ 8.39e+00  3.00e+00]\n",
            " [ 2.82e+01  0.00e+00]\n",
            " [ 7.77e+01  2.80e+01]\n",
            " [ 1.54e+02  1.77e+02]\n",
            " [ 3.38e+00  3.00e+00]\n",
            " [ 1.84e+01  1.50e+01]\n",
            " [ 6.19e+00  9.00e+00]\n",
            " [ 4.37e+01  1.99e+02]\n",
            " [ 4.71e+01  1.10e+01]\n",
            " [ 3.34e+01  8.00e+00]\n",
            " [ 1.97e+00  2.50e+01]\n",
            " [ 2.90e+01  2.10e+01]\n",
            " [ 2.53e+01  1.60e+01]\n",
            " [ 2.79e+01  3.60e+01]\n",
            " [ 6.78e+01  4.70e+01]\n",
            " [ 2.45e+01  3.50e+01]\n",
            " [ 2.77e+01  2.20e+01]\n",
            " [ 5.38e+00  8.00e+00]\n",
            " [ 3.63e+01  0.00e+00]\n",
            " [ 2.11e+01  1.50e+01]\n",
            " [ 1.51e+01  5.00e+01]\n",
            " [ 3.60e+01  7.50e+01]\n",
            " [ 1.97e+01  3.00e+00]\n",
            " [ 7.93e+00  0.00e+00]\n",
            " [ 1.70e+01  4.00e+00]\n",
            " [ 9.48e+01  1.30e+01]\n",
            " [ 1.27e+02  5.00e+01]\n",
            " [ 4.95e+01  4.70e+01]\n",
            " [ 2.02e+01  0.00e+00]\n",
            " [ 3.08e+01  4.00e+00]\n",
            " [ 7.82e+01  9.70e+01]\n",
            " [ 3.45e+01  2.20e+01]\n",
            " [ 3.17e+01  8.00e+00]\n",
            " [ 8.23e+01  3.00e+01]\n",
            " [ 8.66e+01  7.70e+01]\n",
            " [ 5.12e+01  0.00e+00]\n",
            " [ 3.55e+02  0.00e+00]\n",
            " [ 1.33e+02  2.10e+01]\n",
            " [ 6.01e+01  2.80e+01]\n",
            " [ 1.88e+01  0.00e+00]\n",
            " [ 3.37e+01  3.60e+01]\n",
            " [ 3.39e+01  2.00e+01]\n",
            " [ 4.11e+01  1.76e+02]\n",
            " [ 3.01e+01  6.00e+00]\n",
            " [ 5.24e+01  2.50e+01]\n",
            " [ 1.95e+01  8.00e+00]\n",
            " [ 4.50e+02  2.86e+03]\n",
            " [ 2.13e+01  4.00e+00]\n",
            " [ 7.52e+01  4.20e+01]\n",
            " [ 1.73e+01  8.00e+00]\n",
            " [ 2.13e+01  2.30e+01]\n",
            " [ 1.37e+01  1.90e+01]\n",
            " [ 1.17e+02  8.70e+01]\n",
            " [ 4.85e+01  3.70e+01]\n",
            " [ 9.42e+01  9.80e+01]\n",
            " [ 3.38e+01  2.40e+01]\n",
            " [ 2.18e+01  4.00e+00]\n",
            " [ 1.95e+02  5.00e+01]\n",
            " [ 2.89e+01  5.00e+01]\n",
            " [ 6.96e+01  8.00e+00]\n",
            " [ 1.50e+02  2.90e+01]\n",
            " [ 1.48e+01  5.00e+00]\n",
            " [ 9.22e+01  6.40e+01]\n",
            " [ 9.95e+00  1.00e+00]\n",
            " [ 2.47e+01  1.90e+01]\n",
            " [ 1.01e+01  1.00e+00]\n",
            " [ 3.32e+01  1.00e+00]\n",
            " [ 2.82e+01  1.30e+01]\n",
            " [ 2.54e+02  0.00e+00]\n",
            " [ 6.61e+01  4.70e+01]\n",
            " [ 5.53e+01  2.00e+00]\n",
            " [ 2.65e+01  0.00e+00]\n",
            " [ 1.07e+02  1.90e+01]\n",
            " [ 5.67e+02  7.90e+02]\n",
            " [ 5.43e+01  3.40e+01]\n",
            " [ 5.17e+01  7.00e+00]\n",
            " [ 1.96e+01  1.00e+00]\n",
            " [ 3.17e+01  5.10e+01]\n",
            " [ 1.97e+01  3.00e+00]\n",
            " [ 2.52e+02  3.24e+02]\n",
            " [ 6.86e+01  7.40e+01]\n",
            " [ 9.90e+01  3.90e+01]\n",
            " [ 2.74e+02  2.79e+02]\n",
            " [ 1.09e+02  5.20e+01]\n",
            " [ 3.38e+01  3.00e+01]\n",
            " [ 3.64e+01  5.10e+01]\n",
            " [ 4.31e+01  0.00e+00]\n",
            " [ 2.08e+02  1.70e+01]\n",
            " [ 2.84e+01  5.70e+01]\n",
            " [ 1.05e+01  3.00e+00]\n",
            " [-9.98e-01  9.00e+00]\n",
            " [ 2.86e+01  3.00e+00]\n",
            " [ 5.83e+01  1.00e+00]\n",
            " [ 4.27e+01  3.00e+00]\n",
            " [ 4.45e+01  2.40e+01]\n",
            " [ 1.40e+02  2.83e+02]\n",
            " [ 1.48e+02  8.30e+01]\n",
            " [ 8.63e+01  7.70e+01]\n",
            " [ 3.06e+01  2.00e+00]\n",
            " [ 2.85e+01  3.00e+00]\n",
            " [ 4.11e+01  5.00e+00]\n",
            " [ 2.37e+00  2.00e+00]\n",
            " [ 4.84e+01  4.70e+01]\n",
            " [-7.96e+00  0.00e+00]\n",
            " [ 4.46e+02  7.00e+00]\n",
            " [ 2.14e+02  1.37e+03]\n",
            " [ 3.29e+01  3.20e+01]\n",
            " [ 2.68e+02  1.70e+03]\n",
            " [ 1.79e+00  2.00e+00]\n",
            " [ 6.05e+01  1.10e+01]\n",
            " [ 2.02e+01  1.50e+01]\n",
            " [ 2.74e+01  3.80e+01]\n",
            " [ 6.46e+01  2.80e+01]\n",
            " [ 5.22e+01  3.20e+01]\n",
            " [ 3.29e+01  2.50e+01]\n",
            " [ 8.18e+01  3.86e+02]\n",
            " [-1.55e+01  7.00e+00]\n",
            " [ 1.81e+01  2.00e+00]\n",
            " [ 1.84e+01  3.40e+01]\n",
            " [ 4.58e+02  4.66e+02]\n",
            " [-2.66e+01  2.80e+01]\n",
            " [ 3.51e+01  1.30e+01]\n",
            " [ 3.30e+01  2.70e+01]\n",
            " [ 6.88e+01  1.90e+01]\n",
            " [ 4.23e+01  8.50e+01]\n",
            " [ 3.82e+01  4.90e+01]\n",
            " [ 7.94e+01  9.00e+00]\n",
            " [-3.04e-02  3.00e+00]\n",
            " [ 1.21e+02  3.86e+02]\n",
            " [ 2.69e+01  0.00e+00]\n",
            " [ 1.54e+00  8.00e+00]\n",
            " [ 2.80e+01  3.90e+01]\n",
            " [ 3.44e+01  1.40e+01]\n",
            " [ 2.18e+01  1.10e+01]\n",
            " [ 4.05e+00  2.00e+00]\n",
            " [ 2.99e+01  3.30e+01]\n",
            " [ 6.22e+00  0.00e+00]\n",
            " [ 5.94e+01  8.00e+00]\n",
            " [ 2.65e+01  1.00e+00]\n",
            " [ 1.56e+01  7.00e+00]\n",
            " [ 5.90e+01  4.50e+01]\n",
            " [ 2.08e+02  1.00e+01]\n",
            " [ 1.51e+01  4.00e+00]\n",
            " [ 3.20e+01  6.00e+00]\n",
            " [ 7.71e+01  1.30e+01]\n",
            " [ 1.02e+02  1.80e+01]\n",
            " [ 3.76e+02  1.17e+03]\n",
            " [ 9.68e+00  1.10e+01]\n",
            " [ 6.96e+01  7.50e+01]\n",
            " [ 1.10e+02  1.64e+02]\n",
            " [ 7.77e+01  9.00e+00]\n",
            " [ 4.19e+01  5.00e+00]\n",
            " [ 3.18e+01  1.40e+01]\n",
            " [ 4.32e+01  7.00e+01]\n",
            " [ 5.36e+01  1.70e+01]\n",
            " [ 2.53e+01  5.00e+00]\n",
            " [ 1.18e+02  3.66e+02]\n",
            " [ 1.03e+02  5.40e+01]\n",
            " [ 1.04e+02  3.80e+01]\n",
            " [ 3.91e+01  1.30e+01]\n",
            " [ 1.66e+02  5.71e+02]\n",
            " [ 1.33e+01  6.00e+00]\n",
            " [ 6.59e+01  6.00e+00]\n",
            " [ 6.29e+00  7.00e+00]\n",
            " [ 3.69e+00  2.00e+00]\n",
            " [ 1.45e+01  6.00e+00]\n",
            " [-7.71e+00  3.00e+00]\n",
            " [ 4.44e+01  9.30e+01]\n",
            " [ 4.78e+01  3.00e+01]\n",
            " [ 1.32e+02  1.96e+02]\n",
            " [ 7.06e+00  1.40e+01]\n",
            " [ 6.03e+01  9.00e+00]\n",
            " [ 4.88e+02  1.08e+03]\n",
            " [ 6.69e+01  4.20e+01]\n",
            " [ 2.89e+01  2.00e+00]\n",
            " [ 2.06e+01  1.00e+00]\n",
            " [ 6.37e+01  2.00e+00]\n",
            " [ 2.26e+01  1.10e+01]\n",
            " [ 1.22e+01  4.00e+00]\n",
            " [ 2.57e+02  9.80e+01]\n",
            " [ 3.94e+01  1.90e+01]\n",
            " [ 5.40e+01  9.00e+00]\n",
            " [ 3.43e+01  8.00e+00]\n",
            " [ 3.31e+01  2.00e+00]\n",
            " [ 3.22e+01  1.00e+00]\n",
            " [ 4.18e+01  7.00e+01]\n",
            " [ 1.07e+02  2.28e+02]\n",
            " [ 3.87e+01  1.30e+01]\n",
            " [ 2.99e+01  1.18e+02]\n",
            " [ 4.63e+00  1.10e+01]\n",
            " [ 2.14e+01  3.00e+01]\n",
            " [ 2.26e+01  1.00e+01]\n",
            " [ 3.02e+01  1.80e+01]\n",
            " [ 1.56e+01  9.00e+00]\n",
            " [ 5.10e+01  1.32e+02]\n",
            " [ 4.51e+01  9.90e+01]\n",
            " [ 8.50e+01  1.50e+01]\n",
            " [ 2.61e+01  5.00e+00]\n",
            " [ 2.49e+01  1.00e+01]\n",
            " [ 2.16e+01  1.60e+01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Computing R2 value"
      ],
      "metadata": {
        "id": "_jD7KLPDSMKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLkVMrQrSOvt",
        "outputId": "63566d22-75c6-405d-8597-a8d5d00fa600"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3676861695992486"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Applying K-Fold cross validation"
      ],
      "metadata": {
        "id": "CSucf8rLEh7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from numpy import mean\n",
        "from numpy import absolute\n",
        "from numpy import sqrt"
      ],
      "metadata": {
        "id": "Yp_7CCF90WmW"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYbfiITD8ZAz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d749f62-cf52-4b85-f593-4569640c302d"
      },
      "source": [
        "scores = cross_val_score(estimator = regressor, X = X_train, y = y_train, cv = 10, scoring='neg_mean_squared_error')\n",
        "sqrt(mean(absolute(scores)))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "236.65177913564798"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Variance score: %.2f' % regressor.score(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9I4mlBM7Una",
        "outputId": "7dfd448e-0bab-40de-f084-11c8ba177c55"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variance score: 0.37\n"
          ]
        }
      ]
    }
  ]
}